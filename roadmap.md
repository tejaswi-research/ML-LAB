# ðŸ§­ ML Lab â€“ Visual Research Roadmap

This lab evolves by building **visual experiments** that make ML learning visible.
Each block produces a *depiction*, not theory.

```mermaid
flowchart TD

A[Raw Data] --> B[Linear Regression<br/>ðŸ“ˆ Line moves each epoch]
B --> C[Loss Landscape<br/>ðŸ—ºï¸ Learning rate effects]
C --> D[Biasâ€“Variance Tradeoff<br/>âš–ï¸ Underfit â†” Overfit]

D --> E[K-Means Clustering<br/>ðŸŽ¯ Centroids move]
E --> F[Decision Tree<br/>ðŸŒ± Splits grow step-by-step]
F --> G[KNN<br/>ðŸ§­ Neighbourhood influence]

G --> H[Representation Learning<br/>ðŸ§¬ Features transform]
H --> I[Neural Network (1 layer)<br/>ðŸ”„ Hidden representation]
I --> J[PCA<br/>ðŸŒ€ Data compression & rotation]

J --> K[Attention Mechanism<br/>ðŸ”¥ Weight flow]
K --> L[Vision Transformer<br/>ðŸ§© Patches â†’ Attention]
L --> M[Multimodal Fusion<br/>ðŸ”— Vision + Text]

M --> N[Explainable AI<br/>ðŸ” Why this decision?]
N --> O[Counterfactuals<br/>ðŸ”„ What if input changed?]

O --> P[Human-in-the-loop ML<br/>ðŸ¤ User feedback]
P --> Q[Interactive Learning System<br/>ðŸ§  Model adapts with user]
